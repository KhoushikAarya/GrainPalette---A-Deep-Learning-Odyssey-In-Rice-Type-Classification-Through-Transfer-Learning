{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow_hub as hub  # For pre-trained models\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as img\n",
    "import PIL.Image as Image\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import pathlib\n",
    "\n",
    "# Define class labels\n",
    "class_labels = {\n",
    "    'arborio': 0,\n",
    "    'basmati': 1,\n",
    "    'ipsala': 2,\n",
    "    'jasmine': 3,\n",
    "    'karacadag': 4\n",
    "}\n",
    "\n",
    "# File paths of uploaded images\n",
    "image_paths = {\n",
    "    'arborio': \"/mnt/data/Arborio (999).jpg\",\n",
    "    'basmati': \"/mnt/data/basmati (10028).jpg\",\n",
    "    'ipsala': \"/mnt/data/Ipsala (9993).jpg\",\n",
    "    'jasmine': \"/mnt/data/Jasmine (9997).jpg\",\n",
    "    'karacadag': \"/mnt/data/Karacadag (998).jpg\"\n",
    "}\n",
    "\n",
    "# Initialize lists for images and labels\n",
    "X, y = [], []\n",
    "\n",
    "# Preprocess each image\n",
    "for label, path in image_paths.items():\n",
    "    img = cv2.imread(path)\n",
    "    if img is not None:\n",
    "        # Convert to RGB format (since OpenCV loads as BGR)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        # Resize image to (224, 224)\n",
    "        img_resized = cv2.resize(img, (224, 224))\n",
    "        img_resized = img_resized / 255.0  # Normalize\n",
    "        X.append(img_resized)\n",
    "        y.append(class_labels[label])\n",
    "\n",
    "# Convert to numpy arrays\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# One-hot encode labels\n",
    "y = keras.utils.to_categorical(y, num_classes=len(class_labels))\n",
    "\n",
    "# Standardizing images\n",
    "X = np.array(X) / 255.0  # Normalizing pixel values\n",
    "y = np.array(y)  # Converting labels to numpy array\n",
    "\n",
    "# Splitting into Training (70%) and Test + Validation (30%)\n",
    "X_train, X_test_val, y_train, y_test_val = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "# Splitting Test + Validation into separate Validation (15%) and Test (15%)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test_val, y_test_val, test_size=0.5, random_state=42, stratify=y_test_val)\n",
    "\n",
    "# Display dataset sizes\n",
    "print(f\"Training Set: {X_train.shape}, Labels: {y_train.shape}\")\n",
    "print(f\"Validation Set: {X_val.shape}, Labels: {y_val.shape}\")\n",
    "print(f\"Test Set: {X_test.shape}, Labels: {y_test.shape}\")\n",
    "\n",
    "# ---- Preview Images ----\n",
    "fig, axes = plt.subplots(1, 5, figsize=(20, 5))\n",
    "fig.suptitle(\"Rice Categories\")\n",
    "\n",
    "# Extract sample images from the training set\n",
    "sample_labels = [\"Arborio\", \"Basmati\", \"Ipsala\", \"Jasmine\", \"Karacadag\"]\n",
    "for i, ax in enumerate(axes):\n",
    "    ax.imshow(X_train[i])\n",
    "    ax.set_title(sample_labels[np.argmax(y_train[i])])\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# ---- Model Definition ----\n",
    "mobilenet_url = \"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4\"\n",
    "mobile_net = hub.KerasLayer(mobilenet_url, input_shape=(224, 224, 3), trainable=False)\n",
    "\n",
    "num_labels = 5  # Number of classes\n",
    "\n",
    "model = keras.Sequential([\n",
    "    mobile_net,\n",
    "    keras.layers.Dense(num_labels, activation='softmax')\n",
    "])\n",
    "\n",
    "# Model summary\n",
    "model.summary()\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(from_logits=False),\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "# ---- Training the Model ----\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=10,\n",
    "    batch_size=8\n",
    ")\n",
    "\n",
    "# ---- Evaluating the Model ----\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
    "\n",
    "# ---- Plot Training Performance ----\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.title(\"Accuracy Over Epochs\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.title(\"Loss Over Epochs\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
